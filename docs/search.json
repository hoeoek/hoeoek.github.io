[
  {
    "objectID": "posts/citizen_audit/index.html",
    "href": "posts/citizen_audit/index.html",
    "title": "An OSINT approach to citizen audit",
    "section": "",
    "text": "In this post we will have a look at consuming some open data to try to get more enlightened about how a local municipality is run. Sweden is a fairly decent country when it comes to making sure taxpayer money are allocated properly, but every citizens should exercise their right to audit their government whenever possible! You know… just to keep them on their toes.\nUmeå has its own open REST API service where you can find all sorts of data about and from the municipality. It is very well structured and even has a lot of functionality to do some analysis right in the browser. Since we are in love with R, we will skip that and go straight for some .csv-files. I found a some datasets with incoming supplier invoices, which I thought would be an interesting subject for a swift exploratory data analysis.\nDirect links to the .csv’s: 2017, 2018, 2019, 2020, 2021, 2022"
  },
  {
    "objectID": "posts/citizen_audit/index.html#exploring-cleaning-the-data",
    "href": "posts/citizen_audit/index.html#exploring-cleaning-the-data",
    "title": "An OSINT approach to citizen audit",
    "section": "Exploring & cleaning the data:",
    "text": "Exploring & cleaning the data:\nLibraries:\n\nlibrary(tidyverse)\n\nReading and binding together the data into a tibble:\n\ninvoices_raw <- \n  bind_rows(\n    read.csv2(\"leverantorsfakturor-2017.csv\"),\n    read.csv2(\"leverantorsfakturor-2018.csv\"),\n    read.csv2(\"leverantorsfakturor-2019.csv\"),\n    read.csv2(\"leverantorsfakturor-2020.csv\"),\n    read.csv2(\"leverantorsfakturor-2021.csv\"),\n    read.csv2(\"leverantorsfakturor-2022.csv\")\n  ) %>% \n  \n  # Use tibbles because they are awesome\n  tibble() %>% \n  \n  # clean variable names ( <3 janitor!)\n  janitor::clean_names() %>% \n  \n  # select variables of interest & proper classes\n  transmute(\n    across(c(financial_month, \n             verification_number),\n           as.character),\n    across(c(department,\n             supplier,\n             account_text), \n           as.factor),\n    amount = as.numeric(amount))\n\nidentify any duplicates\n\n\nCode\ninvoices_raw %>% \n  filter(duplicated(.)) %>% nrow()\n\n\n[1] 28115\n\n\nIt turns out the dataset has some duplicate records. I’ll put that in the “human error” box and move on, deleting the duplicates. We can also get rid of the verification_number variable.\nLet’s see what we’re working with:\n\n\nCode\ninvoices_clean <- \n  invoices_raw %>% \n  distinct() %>% \n  select(-verification_number)\n\ninvoices_clean %>% skimr::skim_without_charts()\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1982831\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n3\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nfinancial_month\n0\n1\n6\n6\n0\n72\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ndepartment\n0\n1\nFALSE\n19\nTek: 778107, För: 317385, Äld: 257629, Ind: 245531\n\n\nsupplier\n0\n1\nFALSE\n9786\nMar: 126590, TEL: 124618, Ume: 110612, Grö: 77794\n\n\naccount_text\n0\n1\nFALSE\n322\nLiv: 417406, Mob: 118767, Övr: 111842, Elf: 93683\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\namount\n0\n1\n11901.59\n393866.1\n-137600000\n220\n720\n2464.8\n156978099\n\n\n\n\n\nTurns out, the municipality recieved almost 2 million invoices in these six years. That’s quite impressive.\nlooking at skimr output, the invoice amounts looks wierd - let’s plot it and take a look!\n\ninvoices_clean %>% \n  ggplot(aes(amount))+\n  geom_histogram(bins = 50) +\n  scale_x_log10(label = scales::number_format()) +\n  scale_y_continuous(labels = scales::number_format())\n\nWarning in self$trans$transform(x): NaNs produced\n\n\nWarning: Transformation introduced infinite values in continuous x-axis\n\n\nWarning: Removed 83923 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "posts/first_post_beer_label/index.html",
    "href": "posts/first_post_beer_label/index.html",
    "title": "First Post: Beer Label",
    "section": "",
    "text": "In this very first post, I want to totally rush past the part of introducing myself and instead leave that to the About page. However, while the blog will be focused on data science, occasionally other things that I find interesting will sneak in. One of these things is beer, more specifically brewing beer - and what comes along with it. I have been brewing for a few years now and to make them feel a little more like the real deal, I like to design my own labels.\nIn this post I’ll share some R code for creating this map-style minimalist beer label that i recently used for a batch of IPA:\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis is a work in progress, check back in a few days for a more polished post!\n\n\n\n\ntidyverse is the R metapackage to rule them all and includes a bunch of packages that are super useful for data wrangling. It also loads the wonderful magrittr pipe operator (%>%). osmdata is a wrapper for communicating with the Open Street Map API, and sf turns R into a geographic information system (GIS).\n\nlibrary(tidyverse) # The go-to library for basically doing anything in R nowadays\nlibrary(osmdata) # For downloading data from OpenStreetMap\nlibrary(sf) # For working with simple features, such as map stuff\n\n\n\n\nThis beer label will use the road layout for the city of Umeå in the north of Sweden. osmdata has some great functions for this.\n\ngetbb() returns the bounding box (coordinates of the 4 corners of a rectangle) associated with a geographical area.\nopq() builds the database query.\nadd_osm_features() adds, you’ve guessed it, our desired features to the query.\nosmdata_sf() Turns the results of the query into sf format.\n\nI’ll use highway features this time, but check Open Street Maps wiki for other features.\nI’ll separate the roads and streets into two sf features to be able to draw them using different line widths on the label. The output of osmdata_sf() will contain more than we need, so we extract just the line features using purrr::pluck()\n\n#choose area\nbbx <- getbb(\"Umeå, Sweden\")\n\n# large roads\nroads <- bbx %>%\n  opq() %>%\n  add_osm_feature(\n    key = \"highway\",\n    value = c(\"motorway\", \"trunk\", \"primary\",\n              \"secondary\", \"tertiary\", \"motorway_link\",\n              \"trunk_link\", \"primary_link\", \"secondary_link\",\n              \"tertiary_link\")\n    ) %>%\n  osmdata_sf() %>% \n  pluck(\"osm_lines\") \n\n# small roads\nstreets <- bbx %>%\n  opq() %>%\n  add_osm_feature(\n    key = \"highway\",\n    value = c(\"residential\", \"living_street\", \"service\",\n              \"unclassified\", \"pedestrian\", \"footway\",\n              \"track\", \"path\")\n    ) %>%\n  osmdata_sf() %>% \n  pluck(\"osm_lines\") \n\n\n\n\nIn this case I made the map-part of the label have a circular shape, with its center being somewhere downtown Umeå. I’ll get the coordinates non-programmatically (lazy) from just right clicking in Google Maps. Google Maps and OSM use the same coordinate system and projection, so the data smoothly slips into the processing pipeline without any conversion. Happy days.\nSince this is “just” a beer label, I won’t bother too much about dealing with projections - I’ll stick to WGS84/ESPG4326 which should produce good enough visual results.\n\n# make a point that'll be the circle center\ncenter <- c(lat = \"63.82400114332574\", long = \"20.262895955922296\")\n\n# Buffer the point to make the actual circle\ncircle <- tibble(lat = center[\"lat\"], long = center[\"long\"]) %>%\n  st_as_sf(coords = c(\"long\", \"lat\"), crs = 4326) %>%\n  st_buffer(dist = 3500, nQuadSegs = 200)\n\nNow we populate the circle with some roadage:\n\nroads_in_circle <- st_intersection(circle, roads)\nstreets_in_circle <- st_intersection(circle, streets)\n\nAnd plot our simple beer label using ggplot2:\n\nggplot() +\n  \n  # create the thinner streets\n  geom_sf(data = streets_in_circle,\n          linewidth = 0.3,\n          colour = \"gray30\") +\n  \n  # create the thicker streets\n  geom_sf(data = roads_in_circle,\n          linewidth = 0.5,\n          colour = \"gray10\") +\n  \n  # Set some labels\n  labs(title = \"UmeIPA\",\n       caption = \"Northern Made | Dry-Hopped\") +\n  theme_void() + # remove plot objects (x & y axis etc)\n  \n  # Theme our text to make it look fancier\n  theme(\n    plot.title = element_text(\n      family = \"mono\",\n      size = 30,\n      hjust = 0.5,\n      margin = margin(t = 10)\n    ),\n    plot.caption = element_text(\n      family = \"mono\",\n      size = 12,\n      hjust = 0.5,\n      margin = margin(b = 10)\n    )\n  )\n\n\n\n\nTo save it as an image, we may use:\n\nggsave(\"beer_label.png\", height = 6, width = 6, bg = \"white\")\n\nDoesn’t this make the hazy soup that stinks up your basement taste like what love feels like?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Christian Höök",
    "section": "",
    "text": "An OSINT approach to citizen audit\n\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\nChristian\n\n\n\n\n\n\n  \n\n\n\n\nFirst Post: Beer Label\n\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\nChristian\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this blog",
    "section": "",
    "text": "Note\n\n\n\nThis page is currently being worked on. Check back in a few days and it’ll hopefully be neater!\nI am a PhD student working on leveraging machine learning to increase competitiveness for bio-based supply chains. With a strong background in forestry, I have honed my skills in statistical modeling in R and have contributed to research projects, providing data analysis and drone photogrammetry support. My teaching experience includes instructing master-level students in a forestry program, where I shared my passion for data-driven solutions towards enhancing supply chain resilience.\nI believe in the power of open-source technologies to democratize access to essential tools and data, allowing for more effective and inclusive decision-making in the bio-based industry and beyond."
  },
  {
    "objectID": "about.html#toolkit",
    "href": "about.html#toolkit",
    "title": "About this blog",
    "section": "Toolkit",
    "text": "Toolkit\n\nR (Tidyverse, Tidymodels)\nPython\nGIS\nDocker\nQuarto"
  },
  {
    "objectID": "about.html#publications",
    "href": "about.html#publications",
    "title": "About this blog",
    "section": "Publications",
    "text": "Publications\nHöök (2022). Supply and Command: Quantitative Methods for Risk Management and Resilience in Wood Supply. Proceedings of The Joint 44th Annual Meeting of Council on Forest Engineering, the 54th International Symposium on Forest Mechanization. COFE;FORMEC. October 4-7, Corvallis, Oregon. ISBN: 979-8-9855282-1-3. https://www.formec.org/images/proceedings/2022/Proceedings_COFE-FORMEC-IUFRO_2022.pdf [2023-03-20]\nBergstrom et al. (2022). Effects of boom-corridor thinning on harvester productivity and residual stand structure. International Journal of Forest Engineering, 33. https://doi.org/10.1080/14942119.2022.2058258\nHöök (2020). Unmanned aerial vehicle photography and photogrammetry in the Smallwood project. (SmallWood report, November 2020). https://www.smallwood.eu/wp-content/uploads/sites/4/2021/01/SmallWood-Drone-Report_Christian_Hook.pdf [2023-02-18]\nHöök (2020). Promotional video of Smallwood project [Video]. https://www.youtube.com/watch?v=vkZ1UI9yZeo [2022-03-14]\nHöök et al. (2020). A Method of Finding HCT Roundwood Corridors for Reduction of GHG Emissions and Fuel Costs in Sweden. Forests, 11(2). https://doi.org/10.3390/f11020220"
  }
]